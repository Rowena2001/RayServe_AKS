# File name: model_gpu_autoscale_config.yaml
# This configuration file is used to deploy a Hugging Face model on a Ray cluster on AKS with GPU resources.

apiVersion: ray.io/v1alpha1
kind: RayService
metadata:
  name: translator-gpu-auto
spec:
  serviceUnhealthySecondThreshold: 300 # Config for the health check threshold for service. Default value is 60.
  deploymentUnhealthySecondThreshold: 300 # Config for the health check threshold for deployments. Default value is 6
  serveConfig:
    importPath: translator_gpu_autoscale.translator_app
    runtimeEnv: |
      {"working_dir": "https://github.com/Rowena2001/Final_Deployments/archive/refs/tags/latest.zip", 
      "pip": ["torch==1.13.1", "transformers==4.30.2", "accelerate==0.20.3"]}
    deployments:
      - name: Translator
        rayActorOptions:
          numGpus: 0.1
          numCpus: 0.3
  rayClusterConfig:
    # The version of Ray you are using. Make sure all Ray containers are running this version of Ray.
    rayVersion: '2.5.0'
    enableInTreeAutoscaling: true
    # Ray head pod template
    headGroupSpec:
      serviceType: ClusterIP # optional
      # the following params are used to complete the ray start: ray start --head --block ...
      rayStartParams:
        dashboard-host: '0.0.0.0'
      #pod template
      template:
        spec:
          containers:
          # The Ray head container
          - name: ray-head
            image: rayproject/ray-ml:2.5.0-gpu
            ports:
              - containerPort: 6379
                name: gcs-server
              - containerPort: 8265 # Ray dashboard
                name: dashboard
              - containerPort: 10001
                name: client
              - containerPort: 8000
                name: serve
            lifecycle:
              preStop:
                exec:
                  command: ["/bin/sh","-c","ray stop"]
            resources:
              limits:
                nvidia.com/gpu: "1"
                cpu: "2"
                memory: "8Gi"
              requests:
                nvidia.com/gpu: "1"
                cpu: "1"
                memory: "4Gi"
          # tolerations are used to schedule pods if the node has the matching taints (i.e. AKS nodepool taints)
          tolerations:
            - effect: NoSchedule
              key: sku
              value: gpu
              operator: Equal
    workerGroupSpecs:
    # the pod replicas in this group typed worker
    - replicas: 1
      minReplicas: 1
      maxReplicas: 5
      # logical group name, for this called small-group, also can be functional
      groupName: small-group
      rayStartParams: {}
      template:
        spec:
          containers:
          - name: ray-worker
            image: rayproject/ray-ml:2.5.0-gpu
            lifecycle:
              preStop:
                exec:
                  command: ["/bin/sh","-c","ray stop"]
            resources:
              limits:
                nvidia.com/gpu: "1"
                cpu: "3"
                memory: "8Gi"
              requests:
                nvidia.com/gpu: "1"
                cpu: "2"
                memory: "6Gi"
          # tolerations are used to schedule pods if the node has the matching taints (i.e. AKS nodepool taints)
          tolerations:
            - effect: NoSchedule
              key: sku
              value: gpu
              operator: Equal