# File name: model_autoscale_config.yaml
# This configuration file is used to deploy a Hugging Face model on a Ray cluster on AKS with autoscaling.
# automatically create zip file automatically

apiVersion: ray.io/v1alpha1
kind: RayService
metadata:
  name: translator-auto
spec:
  serviceUnhealthySecondThreshold: 300 # Config for the health check threshold for service. Default value is 60.
  deploymentUnhealthySecondThreshold: 300 # Config for the health check threshold for deployments. Default value is 6
  serveConfig:
    importPath: translator_autoscale.translator_app
    runtimeEnv: |
      {"working_dir": "https://github.com/Rowena2001/Final_Deployments/archive/refs/tags/latest.zip", 
      "pip": ["torch==1.13.1", "transformers==4.30.2", "accelerate==0.20.3"]}
    deployments:
      - name: Translator
        rayActorOptions:
          numCpus: 0.5
  rayClusterConfig:
    # The version of Ray you are using. Make sure all Ray containers are running this version of Ray.
    rayVersion: '2.5.0'
    enableInTreeAutoscaling: true
    # Ray head pod template
    headGroupSpec:
      serviceType: ClusterIP # optional
      # the following params are used to complete the ray start: ray start --head --block ...
      rayStartParams:
        dashboard-host: '0.0.0.0'
        # ray-grafana-host: '10.244.2.244:3000'
        # ray-prometheus-host: '10.244.2.244:9090'
      #pod template
      template:
        spec:
          containers:
          # The Ray head container
          - name: ray-head
            image: rowenainternacr.azurecr.io/ray:test-2.5.0
            ports:
              - containerPort: 6379
                name: gcs-server
              - containerPort: 8265 # Ray dashboard
                name: dashboard
              - containerPort: 10001
                name: client
              - containerPort: 8000
                name: serve
            lifecycle:
              preStop:
                exec:
                  command: ["/bin/sh","-c","ray stop"]
            resources:
              limits:
                cpu: "3"
                memory: "2.5G"
              requests:
                cpu: "500m"
                memory: "2G"
          # tolerations are used to schedule pods if the node has the matching taints (i.e. AKS nodepool taints)
          tolerations:
            - effect: NoSchedule
              key: sku
              value: gpu
              operator: Equal
    workerGroupSpecs:
    # the pod replicas in this group typed worker
    - replicas: 2
      minReplicas: 2
      maxReplicas: 10
      # logical group name, for this called small-group, also can be functional
      groupName: small-group
      rayStartParams: {}
      template:
        spec:
          containers:
          - name: ray-worker
            image: rowenainternacr.azurecr.io/ray:test-2.5.0
            lifecycle:
              preStop:
                exec:
                  command: ["/bin/sh","-c","ray stop"]
            resources:
              limits:
                cpu: "2"
                memory: "2G"
              requests:
                cpu: "500m"
                memory: "1G"
          # tolerations are used to schedule pods if the node has the matching taints (i.e. AKS nodepool taints)
          tolerations:
            - effect: NoSchedule
              key: sku
              value: gpu
              operator: Equal